{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEJyFseCSiSn"
      },
      "source": [
        "# T-intersection QMDP\n",
        "In this part you will attempt to formulate the POMDP of T-intersection, and use QMDP to solve it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KJ_nwBUpSShA"
      },
      "outputs": [],
      "source": [
        "# @markdown Run this cell to install dependencies.\n",
        "%%capture\n",
        "\n",
        "% cd /content\n",
        "! git clone https://github.com/buzi-princeton/MDP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcLFgjtzTANC"
      },
      "outputs": [],
      "source": [
        "from MDP.mdp import MDP\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy.stats import beta\n",
        "from scipy.stats import binom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwetIHYCS4CV"
      },
      "source": [
        "# MDP formulation\n",
        "First, create the MDP to capture the underlying MDP of the T-intersection POMDP, using the MDP class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn4pk94PSvvc"
      },
      "outputs": [],
      "source": [
        "# Create the T-intersection MDP\n",
        "class TIntersection(MDP):\n",
        "  def __init__(self):\n",
        "    self.gam = 0.9\n",
        "    self.goal = [\"G1\", \"G2\"]\n",
        "    self.actions = [\"forward\", \"stop\"]\n",
        "    super().__init__(states=[self.goal], actions=self.actions)\n",
        "\n",
        "    self.populate_data()\n",
        "\n",
        "  def populate_data(self):\n",
        "    # use self.add_route(s, a, s') from MDP to add route to MDP\n",
        "    # use self.add_reward(s, a, r) from MDP to add reward\n",
        "    ####\n",
        "    self.add_route([\"G1\"], \"forward\", [\"G1\"], p=0.8)\n",
        "    self.add_route([\"G1\"], \"forward\", [\"G2\"], p=0.2)\n",
        "    self.add_route([\"G2\"], \"forward\", [\"G1\"], p=0.1)\n",
        "    self.add_route([\"G2\"], \"forward\", [\"G2\"], p=0.9)\n",
        "    \n",
        "    self.add_route([\"G1\"], \"stop\", [\"G1\"], p=0.5)\n",
        "    self.add_route([\"G1\"], \"stop\", [\"G2\"], p=0.5)\n",
        "    self.add_route([\"G2\"], \"stop\", [\"G1\"], p=0.05)\n",
        "    self.add_route([\"G2\"], \"stop\", [\"G2\"], p=0.95)\n",
        "\n",
        "    self.add_reward([\"G1\"], \"forward\", 10)\n",
        "    self.add_reward([\"G2\"], \"forward\", -100)\n",
        "    self.add_reward([\"G1\"], \"stop\", -1)\n",
        "    self.add_reward([\"G2\"], \"stop\", -1)\n",
        "    ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQYVairc6KJz"
      },
      "source": [
        "Next, reuse your code for value iteration to solve the underlying MDP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlFucK8YTSyD"
      },
      "outputs": [],
      "source": [
        "# value iteration\n",
        "def value_iteration(threshold = .001, mdp=None):\n",
        "  if mdp is None:\n",
        "    raise ValueError(\"MDP cannot be None\")\n",
        "  numa, nums, R, P = mdp.get_mdp()\n",
        "  V_star = np.zeros(nums)\n",
        "  pi_star = np.zeros(nums)\n",
        "  ####\n",
        "  count = 0\n",
        "  while True:\n",
        "    V_old = V_star\n",
        "    \n",
        "    # compute quality matrix with Q.shape = [num_states, num_actions]\n",
        "    Q = R + mdp.gam * np.einsum(\"jia,j->ia\", P, V_star) # i = current state, j = next state, a = action\n",
        "    # find action with highest quality for each state\n",
        "    pi_star = np.argmax(Q, axis=1)\n",
        "    V_star = Q[range(nums), pi_star]\n",
        "    \n",
        "    # update iteration counter\n",
        "    count += 1\n",
        "    # check convergence\n",
        "    if np.max(np.abs(V_star - V_old)) < threshold:\n",
        "      break\n",
        "  \n",
        "  print(\"Value iteration: {} iterations\".format(count))\n",
        "  ####\n",
        "  return V_star, pi_star"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLGt0X1J6d_D"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "t_intersection = TIntersection()\n",
        "V_star, pi_star = value_iteration(mdp=t_intersection)\n",
        "print(\"V_star: \", V_star)\n",
        "print(\"pi_star: \", pi_star)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hCC5fKa6q2G"
      },
      "source": [
        "## Bayesian Inference\n",
        "Next, we will write the Bayesian update for our belief. Using beta-binomial model to update our belief, assuming that observation for when the other car is heading toward $G_1$ is 0, and 1 when it is heading for $G_2$, write down your prior and your posterior update, choose your prior hyperparameters and reason your choice.\n",
        "\n",
        "We provide you with a **beta_dist** class. Since we are using conjugate prior, the posterior and prior will share the same form, and thus updating the posterior is similar to changing the hyperparameters of the prior to reflect the update. Fill in the missing code for function **update_beta_params()** and **get_mean()**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRkF3BqV6kct"
      },
      "outputs": [],
      "source": [
        "# supporting class for beta distribution\n",
        "\n",
        "class beta_dist:\n",
        "  def __init__(self, a = None, b = None):\n",
        "    self.a = a\n",
        "    self.b = b\n",
        "      \n",
        "  #Get the beta pdf\n",
        "  def get_pdf(self):\n",
        "    x = np.linspace(0, 1, 1000)\n",
        "    fx = beta.pdf(x, self.a, self.b)\n",
        "    dens_dict = {'x': x, 'fx': fx}\n",
        "    return(dens_dict)\n",
        "      \n",
        "  #Update parameters:\n",
        "  def update_beta_params(self, n, num_successes):\n",
        "    ####\n",
        "    self.a += num_successes\n",
        "    self.b += n - num_successes\n",
        "    ####\n",
        "  \n",
        "  def get_mean(self):\n",
        "    ####\n",
        "    return self.a / (self.a + self.b)\n",
        "    ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeW6CoXL71SP"
      },
      "outputs": [],
      "source": [
        "# Test your beta_dist with a batch of observations\n",
        "# create prior using the found hyperparams\n",
        "\n",
        "# define a, b for prior\n",
        "####\n",
        "a = 1\n",
        "b = 1\n",
        "####\n",
        "\n",
        "goal_dist = beta_dist(a, b)\n",
        "prior = goal_dist.get_pdf()\n",
        "\n",
        "# likelihood observation\n",
        "observations = [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
        "\n",
        "# update the distribution\n",
        "goal_dist.update_beta_params(len(observations), sum(observations))\n",
        "posterior = goal_dist.get_pdf()\n",
        "print(\"The updated hyperparameters are:\")\n",
        "print(goal_dist.a, goal_dist.b)\n",
        "\n",
        "# calculate the mean of posterior\n",
        "post_mean = goal_dist.get_mean()\n",
        "\n",
        "print(\"The mean value of our posterior is %s\" %post_mean)\n",
        "\n",
        "#Plot prior and posterior\n",
        "plt.plot(prior['x'], prior['fx'])\n",
        "plt.plot(posterior['x'], posterior['fx'])\n",
        "plt.axvline(x = post_mean, color = \"green\")\n",
        "plt.legend(['Prior Distribution', 'Posterior Distribution', 'Posterior mean'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT1ZVVQf9mCr"
      },
      "source": [
        "Report your posterior mean shift for the following observations\n",
        "* A single **0**\n",
        "* A series of 10 **0**\n",
        "* A series of 10 **1**\n",
        "* 5 **1** and 5 **0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoCu6B_T-EK-"
      },
      "outputs": [],
      "source": [
        "####\n",
        "goal_dist = beta_dist(1, 1)\n",
        "prior_mean = goal_dist.get_mean()\n",
        "print(\"Prior:       ({:2}, {:2}), mean: {:.4f}\".format(goal_dist.a, goal_dist.b, prior_mean))\n",
        "\n",
        "obs1 = [0]\n",
        "goal_dist.update_beta_params(len(obs1), sum(obs1))\n",
        "post1_mean = goal_dist.get_mean()\n",
        "print(\"Posterior 1: ({:2}, {:2}), mean: {:.4f} (shift: {:5.2f})\".format(goal_dist.a, goal_dist.b, post1_mean, post1_mean - prior_mean))\n",
        "\n",
        "obs2 = [0] * 10\n",
        "goal_dist.update_beta_params(len(obs2), sum(obs2))\n",
        "post2_mean = goal_dist.get_mean()\n",
        "print(\"Posterior 1: ({:2}, {:2}), mean: {:.4f} (shift: {:5.2f})\".format(goal_dist.a, goal_dist.b, post2_mean, post2_mean - post1_mean))\n",
        "\n",
        "obs3 = [1] * 10\n",
        "goal_dist.update_beta_params(len(obs3), sum(obs3))\n",
        "post3_mean = goal_dist.get_mean()\n",
        "print(\"Posterior 1: ({:2}, {:2}), mean: {:.4f} (shift: {:5.2f})\".format(goal_dist.a, goal_dist.b, post3_mean, post3_mean - post2_mean))\n",
        "\n",
        "obs4 = [1] * 5 + [0] * 5\n",
        "goal_dist.update_beta_params(len(obs4), sum(obs4))\n",
        "post4_mean = goal_dist.get_mean()\n",
        "print(\"Posterior 1: ({:2}, {:2}), mean: {:.4f} (shift: {:5.2f})\".format(goal_dist.a, goal_dist.b, post4_mean, post4_mean - post3_mean))\n",
        "####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdkKscra-QB8"
      },
      "source": [
        "## QMDP\n",
        "Let's now write the QMDP function to generalize our value calculated before to belief space.\n",
        "\n",
        "First, create an array of beliefs, then write a function that takes in the pre-computed value function, the MDP and the belief to retun a single next best action to take."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98ADnzCR-NLH"
      },
      "outputs": [],
      "source": [
        "def QMDP(V_star, belief, mdp=None):\n",
        "  if mdp is None:\n",
        "    raise ValueError(\"MDP cannot be None\")\n",
        "  \n",
        "  numa, nums, R, P = mdp.get_mdp()\n",
        "\n",
        "  # compute MDP-value for state-action pairs (Q)\n",
        "  ####\n",
        "  # compute quality values\n",
        "  Q = R + mdp.gam * np.einsum(\"jia,j->ia\", P, V_star) # i = current state, j = next state, a = action\n",
        "  # find best action in expectation based on given belief\n",
        "  action = mdp.a[np.argmax(belief @ Q)]\n",
        "  ####\n",
        "  return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvtYrtg6_SHF"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "for p in np.arange(0.0, 1.1, 0.1):\n",
        "  belief = [p, 1 - p]\n",
        "  print(\"Belief: [{:.2f}, {:.2f}]\\tAction to take: \".format(belief[0], belief[1]), QMDP(V_star, belief, mdp=t_intersection))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWGN61Kr_sLD"
      },
      "source": [
        "It can be now seen that we will not go for **forward** action if we are not too sure that the other car will be heading toward G1.\n",
        "\n",
        "Now, we will test QMDP in a real situation. Your car will be at the T-intersection. The intent of the other car will be randomly chosen every time the game is reset (either $G_1$ or $G_2$). You will be able to see our car, running QMDP, either following with our current plan, or waiting for the other car to finish its turn before we continue with our plan.\n",
        "\n",
        "First, let's write some supporting function for the visualizer class that we will be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY_saXR7_oh5"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from MDP.visualizer.t_intesection import TIntersectionSimulation\n",
        "\n",
        "class QMDPTIntersectionVisualizer(TIntersectionSimulation):\n",
        "  def __init__(self, mdp, Q, random_obs=False, seed=None):\n",
        "    self.random_obs = random_obs\n",
        "    self.seed = seed\n",
        "    \n",
        "    self.goal_dist = beta_dist(1, 1)\n",
        "    super().__init__(mdp, Q)\n",
        "  \n",
        "    self.obs1_prob = { # probability for making observation 1 (G2)\n",
        "        0: [0.5] * 20 + list(np.linspace(0.5, 0.0, 20)), # true_state = G1\n",
        "        1: [0.5] * 4  + [0.6, 0.6, 0.7, 0.7, 0.8, 0.95], # true_state = G2\n",
        "    }\n",
        "    self.observations = []\n",
        "    if self.random_obs and self.seed is not None:\n",
        "      random.seed(self.seed)\n",
        "  \n",
        "  def reset(self):\n",
        "    # reset our self.goal_dist to initial prior\n",
        "    # reset our belief to initial probability\n",
        "\n",
        "    ####\n",
        "    self.goal_dist = beta_dist(1, 1) # uniform distribution\n",
        "    self.belief = [self.goal_dist.get_mean(), 1 - self.goal_dist.get_mean()] # or [0.5, 0.5]\n",
        "    \n",
        "    self.observations = []\n",
        "    if self.random_obs and self.seed is not None:\n",
        "      random.seed(self.seed)\n",
        "    ####\n",
        "\n",
        "    # randomize the true_state, this will be used as our observation, if not be \n",
        "    # overwritten later\n",
        "    self.true_state = np.random.choice(self.mdp.num_s)\n",
        "    self.t = 0\n",
        "    self.our_t = 0\n",
        "  \n",
        "  def update_belief(self, observation):\n",
        "    # update the distribution\n",
        "    # use the observation input to update our self.goal_dist, which is an object\n",
        "    # of the beta_dist that we used before\n",
        "    ####\n",
        "    # randomize observations\n",
        "    if self.random_obs:\n",
        "      obs_count = len(self.observations)\n",
        "      if obs_count < len(self.obs1_prob[observation]):\n",
        "        observation = 1 if random.random() < self.obs1_prob[observation][obs_count] else 0\n",
        "    \n",
        "    self.observations.append(observation)\n",
        "    self.goal_dist.update_beta_params(1, 1 - observation)  # success = observation 0 (i.e. other truck goes to G1)\n",
        "    self.belief = [self.goal_dist.get_mean(), 1 - self.goal_dist.get_mean()]\n",
        "    ####\n",
        "  \n",
        "  def get_next_action(self):\n",
        "    # return a single next best action based on current belief and Q\n",
        "    \n",
        "    ####\n",
        "    return np.argmax(self.belief @ self.Q)\n",
        "    ####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LlyBa3zJ9Ba"
      },
      "source": [
        "Let's create 2 GIFs files for each case of true state (0 for $G_1$ and 1 for $G_2$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m43-2AbJHr-"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "from IPython.display import Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Get the Q value to pass to the visualizer\n",
        "####\n",
        "Q = t_intersection.R + t_intersection.gam * np.einsum(\"jia,j->ia\", t_intersection.P, V_star)\n",
        "####\n",
        "t_intersection_simulation = QMDPTIntersectionVisualizer(t_intersection, Q, random_obs=False, seed=0)\n",
        "\n",
        "# reset your true state here\n",
        "true_state = 0\n",
        "\n",
        "folder = \"figure\"\n",
        "sub_folder = \"qmdp-{}\".format(true_state)\n",
        "sub_folder_pdf = \"qmdp-{}-pdf\".format(true_state)\n",
        "sub_folder_results = \"results\"\n",
        "\n",
        "fig_folder = os.path.join(\"/content\", folder)\n",
        "fig_prog_folder = os.path.join(fig_folder, sub_folder)\n",
        "fig_prog_folder_pdf = os.path.join(fig_folder, sub_folder_pdf)\n",
        "fig_results_folder = os.path.join(fig_folder, sub_folder_results)\n",
        "os.makedirs(fig_prog_folder, exist_ok=True)\n",
        "os.makedirs(fig_prog_folder_pdf, exist_ok=True)\n",
        "os.makedirs(fig_results_folder, exist_ok=True)\n",
        "\n",
        "t_intersection_simulation.reset()\n",
        "t_intersection_simulation.set_true_state(true_state)\n",
        "\n",
        "for i in tqdm(range(60)):\n",
        "  t_intersection_simulation.step()\n",
        "  t_intersection_simulation.plot()\n",
        "  plt.text(10, 28, \"Observation count: {}\".format(len(t_intersection_simulation.observations)))\n",
        "  plt.savefig(os.path.join(fig_prog_folder, \"{}.png\".format(i)), dpi=75)\n",
        "  plt.clf()\n",
        "\n",
        "  pdf = t_intersection_simulation.goal_dist.get_pdf()\n",
        "  pdf_mean = t_intersection_simulation.goal_dist.get_mean()\n",
        "  plt.plot(1 - pdf['x'], pdf['fx'])\n",
        "  plt.axvline(x = 1 - pdf_mean, color = \"green\")\n",
        "  plt.title(\"Belief for $G_2$\")\n",
        "  plt.legend(['Posterior Distribution', 'Posterior mean'], loc='upper left')\n",
        "  plt.savefig(os.path.join(fig_prog_folder_pdf, \"{}.png\".format(i)), dpi=75)\n",
        "  plt.clf()\n",
        "\n",
        "print(\"Observations: {}\".format(t_intersection_simulation.observations))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "cellView": "form",
        "id": "-VABk8TkfZTR"
      },
      "outputs": [],
      "source": [
        "#@title { run: \"auto\" , form-width: \"30%\"}\n",
        "#@markdown # Set experiment tag for snapshot\n",
        "\n",
        "experiment_tag = \"A0\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OQMwYrCkopM"
      },
      "outputs": [],
      "source": [
        "gif_path = os.path.join(fig_results_folder, '{}_{}.gif'.format(experiment_tag, true_state))\n",
        "length = len([i for i in os.listdir(os.path.join(fig_prog_folder)) if \".png\" in i])\n",
        "\n",
        "with imageio.get_writer(gif_path, mode='I') as writer:\n",
        "  for i in tqdm(range(length)):\n",
        "    print(i, end='\\r')\n",
        "    filename = os.path.join(fig_prog_folder, str(i)+\".png\")\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "\n",
        "gif_pdf_path = os.path.join(fig_results_folder, '{}_{}_pdf.gif'.format(experiment_tag, true_state))\n",
        "length = len([i for i in os.listdir(os.path.join(fig_prog_folder_pdf)) if \".png\" in i])\n",
        "\n",
        "with imageio.get_writer(gif_pdf_path, mode='I') as writer:\n",
        "  for i in tqdm(range(length)):\n",
        "    print(i, end='\\r')\n",
        "    filename = os.path.join(fig_prog_folder_pdf, str(i)+\".png\")\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "\n",
        "display(Image(open(gif_path,'rb').read(), width=400))\n",
        "display(Image(open(gif_pdf_path,'rb').read(), width=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg1tT0lUo2hd"
      },
      "outputs": [],
      "source": [
        "# !zip /content/results.zip /content/figure/results/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HT9W6D2hBOI"
      },
      "source": [
        "## Task 2: Simulation Results\n",
        "\n",
        "### A. Results under ideal observations\n",
        "In this experiment, our own truck always observes the true state. Hence, the belief about the state of the other truck increases monotonically for the true state.\n",
        "\n",
        "\\#| \\| |(G1, forward)|(G2, forward)|(G1, stop)|(G2, stop)| \\| |forward|stop| \\| |remark\n",
        "-| - |-|-|-|-| - |-|-| - |-\n",
        "A0| \\| |[0.8, 0.2]|[0.1, 0.9]|[0.5, 0.5]|[0.05, 0.95]| \\| |[10, -100]|[-1, -1]| \\| |\n",
        "A1| \\| |**[0.9, 0.1]**|**[0.6, 0.4]**|[0.5, 0.5]|[0.05, 0.95]| \\| |[10, -100]|[-1, -1]| \\| | *less conservative (more prob. on s' = G1)*\n",
        "A2| \\| |**[0.9, 0.1]**|**[0.9, 0.1]**|[0.5, 0.5]|[0.05, 0.95]| \\| |[10, -100]|[-1, -1]| \\| | *less conservative (more prob. on s' = G1)*\n",
        "A3| \\| |**[0.9, 0.1]**|**[0.9, 0.1]**|[0.5, 0.5]|[0.05, 0.95]| \\| |**[10, -10]**|[-1, -1]| \\| | *collision (more prob. on s' = G1, higher reward for forward)*\n",
        "A4| \\| |**[0.9, 0.1]**|**[0.9, 0.1]**|[0.5, 0.5]|[0.05, 0.95]| \\| |[10, -100]|**[-14, -14]**| \\| | *almost collision (more prob. on s' = G1, smaller reward for stop)*\n",
        "\n",
        "### B. Results under more realistic observations\n",
        "In this experiment, we randomize the observations of our own truck and increase the probability of observing the true state over time. This increases the uncertainty in the belief about the state of the other truck.\n",
        "\n",
        "\\#| \\| |(G1, forward)|(G2, forward)|(G1, stop)|(G2, stop)| \\| |forward|stop| \\| |remark\n",
        "-| - |-|-|-|-| - |-|-| - |-\n",
        "B0| \\| |[0.8, 0.2]|[0.1, 0.9]|[0.5, 0.5]|[0.05, 0.95]| \\| |[10, -100]|[-1, -1]| \\| | *too conservative, does not move (higher uncertainty for s' = G1)*\n",
        "B1| \\| |[0.8, 0.2]|[0.1, 0.9]|[0.5, 0.5]|[0.05, 0.95]| \\| |**[10, -50]**|[-1, -1]| \\| | *conservative, starts moving very late*\n",
        "B2| \\| |[0.8, 0.2]|[0.1, 0.9]|[0.5, 0.5]|[0.05, 0.95]| \\| |**[10, -10]**|[-1, -1]| \\| | *almost collision*\n",
        "B3| \\| |[0.8, 0.2]|[0.1, 0.9]|[0.5, 0.5]|[0.05, 0.95]| \\| |[10, -100]|**[-14, -14]**| \\| | *less conservative, starts moving earlier*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ECE346_SP22_Lab3_QMDP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
