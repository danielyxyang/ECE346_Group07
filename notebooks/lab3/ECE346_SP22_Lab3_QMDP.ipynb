{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab3_QMDP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfimhNRaZ8ymkw/Rt9fQXB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# T-intersection QMDP\n","In this part you will attempt to formulate the POMDP of T-intersection, and use QMDP to solve it."],"metadata":{"id":"ZEJyFseCSiSn"}},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"KJ_nwBUpSShA","executionInfo":{"status":"ok","timestamp":1649252615340,"user_tz":240,"elapsed":1147,"user":{"displayName":"Duy Nguyen","userId":"08033384467030747105"}}},"outputs":[],"source":["# @markdown Run this cell to install dependencies.\n","%%capture\n","\n","% cd /content\n","! git clone https://github.com/buzi-princeton/MDP.git"]},{"cell_type":"code","source":["from MDP.mdp import MDP\n","import numpy as np\n","import os\n","from scipy.stats import beta\n","from scipy.stats import binom"],"metadata":{"id":"ZcLFgjtzTANC","executionInfo":{"status":"ok","timestamp":1649252624013,"user_tz":240,"elapsed":488,"user":{"displayName":"Duy Nguyen","userId":"08033384467030747105"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# MDP formulation\n","First, create the MDP to capture the underlying MDP of the T-intersection POMDP, using the MDP class."],"metadata":{"id":"vwetIHYCS4CV"}},{"cell_type":"code","source":["# Create the T-intersection MDP\n","class TIntersection(MDP):\n","  def __init__(self):\n","    self.gam = 0.9\n","    self.goal = [\"G1\", \"G2\"]\n","    self.actions = [\"forward\", \"stop\"]\n","    super().__init__(states=[self.goal], actions=self.actions)\n","\n","    self.populate_data()\n","\n","  def populate_data(self):\n","    # use self.add_route(s, a, s') from MDP to add route to MDP\n","    # use self.add_reward(s, a, r) from MDP to add reward\n","    ####\n","    ## YOUR CODE HERE\n","    raise NotImplementedError(\"Your TIntersection MDP is empty!\")\n","    ####"],"metadata":{"id":"Yn4pk94PSvvc","executionInfo":{"status":"ok","timestamp":1649252637351,"user_tz":240,"elapsed":271,"user":{"displayName":"Duy Nguyen","userId":"08033384467030747105"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Next, reuse your code for value iteration to solve the underlying MDP"],"metadata":{"id":"PQYVairc6KJz"}},{"cell_type":"code","source":["# value iteration\n","def value_iteration(threshold = .001, mdp=None):\n","  if mdp is None:\n","    raise ValueError(\"MDP cannot be None\")\n","  numa, nums, R, P = mdp.get_mdp()\n","  V_star = np.zeros(nums)\n","  pi_star = np.zeros(nums)\n","  ####\n","  ## YOUR CODE HERE\n","  raise NotImplementedError(\"Your value iteration is empty!\")\n","  ####\n","  return V_star, pi_star"],"metadata":{"id":"IlFucK8YTSyD","executionInfo":{"status":"ok","timestamp":1649252640982,"user_tz":240,"elapsed":351,"user":{"displayName":"Duy Nguyen","userId":"08033384467030747105"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Test\n","t_intersection = TIntersection()\n","V_star, pi_star = value_iteration(mdp=t_intersection)\n","print(\"V_star: \", V_star)\n","print(\"pi_star: \", pi_star)"],"metadata":{"id":"sLGt0X1J6d_D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bayesian Inference\n","Next, we will write the Bayesian update for our belief. Using beta-binomial model to update our belief, assuming that observation for when the other car is heading toward $G_1$ is 0, and 1 when it is heading for $G_2$, write down your prior and your posterior update, choose your prior hyperparameters and reason your choice.\n","\n","We provide you with a **beta_dist** class. Since we are using conjugate prior, the posterior and prior will share the same form, and thus updating the posterior is similar to changing the hyperparameters of the prior to reflect the update. Fill in the missing code for function **update_beta_params()** and **get_mean()**."],"metadata":{"id":"9hCC5fKa6q2G"}},{"cell_type":"code","source":["# supporting class for beta distribution\n","\n","class beta_dist:\n","  def __init__(self, a = None, b = None):\n","    self.a = a\n","    self.b = b\n","      \n","  #Get the beta pdf\n","  def get_pdf(self):\n","    x = np.linspace(0, 1, 1000)\n","    fx = beta.pdf(x, self.a, self.b)\n","    dens_dict = {'x': x, 'fx': fx}\n","    return(dens_dict)\n","      \n","  #Update parameters:\n","  def update_beta_params(self, n, num_successes):\n","    ####\n","    ## YOUR CODE HERE\n","    raise NotImplementedError(\"Your posterior update is empty!\")\n","    ####\n","  \n","  def get_mean(self):\n","    ####\n","    ## YOUR CODE HERE\n","    raise NotImplementedError(\"Your mean function is empty!\")\n","    ####"],"metadata":{"id":"oRkF3BqV6kct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test your beta_dist with a batch of observations\n","# create prior using the found hyperparams\n","\n","# define a, b for prior\n","####\n","## YOUR CODE HERE\n","raise NotImplementedError(\"Missing a, b for prior\")\n","a = None\n","b = None\n","####\n","\n","goal_dist = beta_dist(a, b)\n","prior = goal_dist.get_pdf()\n","\n","# likelihood observation\n","observations = [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n","\n","# update the distribution\n","goal_dist.update_beta_params(len(observations), sum(observations))\n","posterior = goal_dist.get_pdf()\n","print(\"The updated hyperparameters are:\")\n","print(goal_dist.a, goal_dist.b)\n","\n","# calculate the mean of posterior\n","post_mean = goal_dist.get_mean()\n","\n","print(\"The mean value of our posterior is %s\" %post_mean)\n","\n","#Plot prior and posterior\n","plt.plot(prior['x'], prior['fx'])\n","plt.plot(posterior['x'], posterior['fx'])\n","plt.axvline(x = post_mean, color = \"green\")\n","plt.legend(['Prior Distribution', 'Posterior Distribution', 'Posterior mean'], loc='upper left')\n","\n","plt.show()"],"metadata":{"id":"yeW6CoXL71SP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Report your posterior mean shift for the following observations\n","* A single **0**\n","* A series of 10 **0**\n","* A series of 10 **1**\n","* 5 **1** and 5 **0**"],"metadata":{"id":"eT1ZVVQf9mCr"}},{"cell_type":"code","source":["####\n","## YOUR CODE HERE\n","raise NotImplementedError(\"Report the posterior mean for 4 cases\")\n","\n","####"],"metadata":{"id":"MoCu6B_T-EK-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## QMDP\n","Let's now write the QMDP function to generalize our value calculated before to belief space.\n","\n","First, create an array of beliefs, then write a function that takes in the pre-computed value function, the MDP and the belief to retun a single next best action to take."],"metadata":{"id":"OdkKscra-QB8"}},{"cell_type":"code","source":["def QMDP(V_star, belief, mdp=None):\n","  if mdp is None:\n","    raise ValueError(\"MDP cannot be None\")\n","  \n","  numa, nums, R, P = mdp.get_mdp()\n","\n","  # compute MDP-value for state-action pairs (Q)\n","  ####\n","  ## YOUR CODE HERE\n","  raise NotImplementedError(\"Your QMDP function is empty\")\n","\n","  ####\n","  return None"],"metadata":{"id":"98ADnzCR-NLH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test\n","for p in np.arange(0.0, 1.1, 0.1):\n","  belief = [p, 1 - p]\n","  print(\"Belief: [{:.2f}, {:.2f}]\\tAction to take: \".format(belief[0], belief[1]), QMDP(V_star, belief, mdp=t_intersection))"],"metadata":{"id":"PvtYrtg6_SHF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["It can be now seen that we will not go for **forward** action if we are not too sure that the other car will be heading toward G1.\n","\n","Now, we will test QMDP in a real situation. Your car will be at the T-intersection. The intent of the other car will be randomly chosen every time the game is reset (either $G_1$ or $G_2$). You will be able to see our car, running QMDP, either following with our current plan, or waiting for the other car to finish its turn before we continue with our plan.\n","\n","First, let's write some supporting function for the visualizer class that we will be using."],"metadata":{"id":"ZWGN61Kr_sLD"}},{"cell_type":"code","source":["from MDP.visualizer.t_intesection import TIntersectionSimulation\n","\n","class QMDPTIntersectionVisualizer(TIntersectionSimulation):\n","  def __init__(self, mdp, Q):\n","    \n","    self.goal_dist = beta_dist(1, 1)\n","    super().__init__(mdp, Q)\n","  \n","  def reset(self):\n","    # reset our self.goal_dist to initial prior\n","    # reset our belief to initial probability\n","\n","    ####\n","    ## YOUR CODE HERE\n","    raise NotImplementedError(\"reset is not done\")\n","    \"\"\"\n","    self.goal_dist = ...\n","    self.belief = ...\n","    \"\"\"\n","    ####\n","\n","    # randomize the true_state, this will be used as our observation, if not be \n","    # overwritten later\n","    self.true_state = np.random.choice(self.mdp.num_s)\n","    self.t = 0\n","    self.our_t = 0\n","  \n","  def update_belief(self, observation):\n","    # update the distribution\n","    # use the observation input to update our self.goal_dist, which is an object\n","    # of the beta_dist that we used before\n","    ####\n","    ## YOUR CODE HERE\n","    raise NotImplementedError(\"update_belief is empty\")\n","    \"\"\"\n","    self.goal_dist.update_beta_params(..., ...)\n","    self.belief = None\n","    \"\"\"\n","    ####\n","  \n","  def get_next_action(self):\n","    # return a single next best action based on current belief and Q\n","    \n","    ####\n","    ## YOUR CODE HERE\n","    raise NotImplementedError(\"get_next_action cannot be none\")\n","\n","    ####"],"metadata":{"id":"qY_saXR7_oh5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's create 2 GIFs files for each case of true state (0 for $G_1$ and 1 for $G_2$)."],"metadata":{"id":"0LlyBa3zJ9Ba"}},{"cell_type":"code","source":["import imageio\n","from IPython.display import Image\n","from tqdm.notebook import tqdm\n","\n","# Get the Q value to pass to the visualizer\n","####\n","## YOUR CODE HERE\n","raise NotImplementedError(\"Q cannot be none\")\n","Q = None\n","####\n","t_intersection_simulation = QMDPTIntersectionVisualizer(t_intersection, Q)\n","\n","# reset your true state here\n","true_state = 0\n","\n","folder = \"figure\"\n","sub_folder = \"qmdp-{}\".format(true_state)\n","\n","fig_folder = os.path.join(\"/content\", folder)\n","fig_prog_folder = os.path.join(fig_folder, sub_folder)\n","os.makedirs(fig_prog_folder, exist_ok=True)\n","\n","t_intersection_simulation.reset()\n","t_intersection_simulation.set_true_state(true_state)\n","\n","for i in tqdm(range(100)):\n","  t_intersection_simulation.step()\n","  t_intersection_simulation.plot()\n","  plt.savefig(os.path.join(fig_prog_folder, \"{}.png\".format(i)), dpi=200)\n","  plt.clf()\n","\n","gif_path = os.path.join(fig_prog_folder, 'result.gif')\n","length = len([i for i in os.listdir(os.path.join(fig_prog_folder)) if \".png\" in i])\n","\n","with imageio.get_writer(gif_path, mode='I') as writer:\n","  for i in tqdm(range(length)):\n","    print(i, end='\\r')\n","    filename = os.path.join(fig_prog_folder, str(i)+\".png\")\n","    image = imageio.imread(filename)\n","    writer.append_data(image)\n","Image(open(gif_path,'rb').read(), width=400)"],"metadata":{"id":"9m43-2AbJHr-"},"execution_count":null,"outputs":[]}]}