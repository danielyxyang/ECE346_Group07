{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab3_MDP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOJexvjLUXlXE5OV6DclD87"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Passenger pick up MDP\n","In this part you will attempt to formulate the MDP of our Minicity to solve the passenger pick up problem using Value Iteration and Policy Iteration."],"metadata":{"id":"htT-8pxNJb7T"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sJxurl6iCc08","cellView":"form"},"outputs":[],"source":["# @markdown Run this cell to install dependencies.\n","%%capture\n","\n","% cd /content\n","! git clone https://github.com/buzi-princeton/MDP.git"]},{"cell_type":"code","source":["from MDP.mdp import MDP\n","from MDP.visualizer.minicity import MinicityVisualizer\n","import numpy as np\n","import os"],"metadata":{"id":"czsa9bXaCl42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @markdown Run this cell to test our dependencies.\n","# TEST\n","# Run the following test to see if your MDP code fetch is working\n","print(\"Test MDP class\")\n","a = [1, 2, 3, 4]\n","b = [5, 6, 7, 8]\n","c = [23, 24, 25]\n","\n","mdp = MDP(states=[a, b, c], actions=[1,2,3,4])\n","\n","for i in range(4*4*3):\n","  state = mdp.get_state(i)\n","  real_state = mdp.get_real_state_value(i)\n","  index = mdp.get_index(real_state)\n","  if i != index:\n","    raise ValueError(\"Something is wrong\")\n","  if i%10==0:\n","    print(i, state, real_state, index)\n","\n","print(\"Everything is correct!\")\n","print(\"\\nTest Minicity Visualizer\")\n","\n","import os\n","\n","folder = \"figure\"\n","sub_folder = \"minicity\"\n","\n","fig_folder = os.path.join(\"/content\", folder)\n","fig_prog_folder = os.path.join(fig_folder, sub_folder)\n","os.makedirs(fig_prog_folder, exist_ok=True)\n","\n","visualizer = MinicityVisualizer(fig_prog_folder=fig_prog_folder)\n","visualizer.reset(current_pos=0, goal=6)\n","visualizer.plot()\n","for i in range(1, 7):\n","    visualizer.update_pos(i)\n","\n","import imageio\n","from IPython.display import Image\n","from tqdm.notebook import tqdm\n","\n","gif_path = os.path.join(fig_prog_folder, 'result.gif')\n","length = len([i for i in os.listdir(os.path.join(fig_prog_folder)) if \".png\" in i])\n","\n","with imageio.get_writer(gif_path, mode='I') as writer:\n","  for i in tqdm(range(length)):\n","    print(i, end='\\r')\n","    filename = os.path.join(fig_prog_folder, str(i)+\".png\")\n","    image = imageio.imread(filename)\n","    writer.append_data(image)\n","Image(open(gif_path,'rb').read(), width=400)"],"metadata":{"id":"fmd_MJy4IwzY","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MDP formulation of Minicity\n","\n","Below is the sample 2-state MDP as discussed in lab 3 handout. Try to run the below code and play around to understand how MDP class works."],"metadata":{"id":"zme0yUfFKfzD"}},{"cell_type":"code","source":["class TwoStateMDP(MDP):\n","  def __init__(self):\n","    self.states = [\"s1\", \"s2\"]\n","    self.actions = [\"a0\", \"a1\"]\n","    self.gam = 0.9\n","    \n","    # call the parent class\n","    # notice that the state is a list of state variables\n","    super().__init__(\n","      states=[self.states], actions=self.actions)\n","    self.populate_data()\n","    \n","  def populate_data(self):\n","    # add all routes from s1\n","    self.add_route([\"s1\"],\"a0\",[\"s1\"])\n","    self.add_route([\"s1\"],\"a1\",[\"s2\"])\n","    # add all routes from s2\n","    self.add_route([\"s2\"],\"a0\",[\"s2\"])\n","    self.add_route([\"s2\"],\"a1\",[\"s2\"])\n","    \n","    # let's populate the reward, assuming r>0 is 0.5\n","    for a in self.a:\n","      self.add_reward([\"s1\"],a,0.5)\n","      self.add_reward([\"s2\"],a,1.5)\n","\n","twoStateMDP = TwoStateMDP()\n","print(twoStateMDP.get_index([\"s1\"]))\n","print(twoStateMDP.get_state(0))\n","print(twoStateMDP.get_real_state_value(0))"],"metadata":{"id":"i2oognBAKiPd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's try to build our Minicity MDP.\n","We have 1 positional state variable $p_{cur}$, 1 directional state variable $d$ and 1 goal state variable $p_{goal}$.\n","$s = \\{p_{cur}, d,  p_{goal}\\}$\n","\n","$p_{cur} \\in \\{0â€¦6\\},  p_{goal} \\in \\{3, 4, 5, 6\\}$,  and \n","$d \\in \\{cw, ccw\\}$"],"metadata":{"id":"kpiGg8KRK6Q7"}},{"cell_type":"code","source":["class Minicity(MDP):\n","  def __init__(self):\n","    self.positional_states = [0, 1, 2, 3, 4, 5, 6]\n","    self.goal_states = [3, 4, 5, 6]\n","    self.directional_states = [\"cw\", \"ccw\"]\n","    self.actions = [\"forward\", \"left\", \"right\", \"switch\"]\n","    self.gam = 0.9\n","\n","    super().__init__(states=[self.positional_states, self.directional_states, self.goal_states], actions=self.actions)\n","    \n","    self.populate_data()\n","  \n","  def populate_data(self):\n","    # populate state transition function and reward function\n","    ####\n","    ## YOUR CODE HERE\n","    raise NotImplementedError(\"Your Minicity MDP is empty!\")\n","    ####"],"metadata":{"id":"qBhX6vqYK2fS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Value and Policy Iteration\n","Let's now write the value iteration and policy iteration method"],"metadata":{"id":"6lBDhHfZLult"}},{"cell_type":"code","source":["def value_iteration(threshold = .001, mdp=None):\n","  if mdp is None:\n","    raise ValueError(\"MDP cannot be None\")\n","  numa, nums, R, P = mdp.get_mdp()\n","  V_star = np.zeros(nums)\n","  pi_star = np.zeros(nums)\n","  \n","  ####\n","  ## YOUR CODE HERE\n","  raise NotImplementedError(\"You have not written Value Iteration\")\n","  ####\n","\n","  return V_star, pi_star\n","\n","def policy_eval(policy, threshold = .001, mdp=None):\n","  if mdp is None:\n","    raise ValueError(\"MDP cannot be None\")\n","  numa, nums, R, P = mdp.get_mdp()\n","  V = np.zeros(nums)\n","  \n","  ####\n","  ## YOUR CODE HERE\n","  raise NotImplementedError(\"You have not written Policy Evaluation\")\n","  ####\n","\n","  return V\n","\n","def policy_iteration(threshold = .001, mdp=None):\n","  if mdp is None:\n","    raise ValueError(\"MDP cannot be None\")\n","  numa, nums, R, P = mdp.get_mdp()\n","  # initialize a random policy with length nums and action randomly assigned from numa\n","  pi_star = np.random.randint(0, numa, nums)\n","  V_star = np.zeros(nums)\n","  \n","  ####\n","  ## YOUR CODE HERE\n","  raise NotImplementedError(\"You have not written Policy Iteration\")\n","  ####\n","  \n","  return V_star, pi_star"],"metadata":{"id":"LRSKM1uyLzTq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run the below code to test your written Value iteration and Policy iteration. You should have similar optimal policy across the two methods."],"metadata":{"id":"76tCE4P6Qh1a"}},{"cell_type":"code","source":["# Test policy and value iteration\n","minicity = Minicity()\n","V_star_value, pi_star_value = value_iteration(mdp=minicity)\n","print(\"Value iteration\")\n","print(\"V_star: \", V_star_value)\n","print(\"pi_star: \", pi_star_value)\n","\n","V_star_policy, pi_star_policy = policy_iteration(mdp=minicity)\n","print(\"Policy iteration\")\n","print(\"V_star: \", V_star_policy)\n","print(\"pi_star: \", pi_star_policy)\n","\n","if not np.array_equal(pi_star_value, pi_star_policy):\n","  print(\"Warning: Your pi_star between value iteration and policy iteration is different!\")\n","  print(\"Try to run these two different policies in the next test case to see if it makes sense\")"],"metadata":{"id":"cu7B-SvAPhHt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's now try to use the computed policy into solving our Minicity passenger pick up MDP. Given the initial state $s=[1, cw, 6]$, what should be the sequence of actions taken, and what is the cumulative reward?"],"metadata":{"id":"ZaHus0tNQuIb"}},{"cell_type":"code","source":["# Test pi_star\n","minicity = Minicity()\n","V_star, pi_star = value_iteration(mdp=minicity)\n","print(\"V_star: \", V_star)\n","print(\"pi_star: \", pi_star)\n","\n","# Test calculated pi_star\n","state = [1, \"cw\", 6]\n","\n","while True:\n","  # get the next action from pi_star\n","  # get next state, and continue until we get to the goal\n","  # display the reward, and the actions taken so far \n","  # to solve initial state [1, \"cw\", 6]\n","  ####\n","  ## YOUR CODE HERE\n","  raise NotImplementedError(\n","      \"You have not written the test loop for your calculated pi_star\")\n","  ####\n","  \n","  if state[0] == state[2]:\n","    break"],"metadata":{"id":"cxCyM5kDLI97"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# figure folder\n","folder = \"figure\"\n","sub_folder = \"minicity\"\n","\n","fig_folder = os.path.join(\"/content\", folder)\n","fig_prog_folder = os.path.join(fig_folder, sub_folder)\n","os.makedirs(fig_prog_folder, exist_ok=True)"],"metadata":{"id":"A2V-x7pHM5lD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Checkpoint 1\n","Put everything together, let's run 5 continuous random test cases and make a beautiful GIF of our car moving in the Minicity to pick up passengers!"],"metadata":{"id":"rnveftEZRHVl"}},{"cell_type":"code","source":["import random\n","from tqdm.notebook import tqdm\n","\n","visualizer = MinicityVisualizer(fig_prog_folder=fig_prog_folder)\n","\n","for i in tqdm(range(5)):\n","  converged = False\n","  goal = random.choice([3, 4, 5, 6])\n","  pos = random.choice([0, 1, 2, 3, 4, 5, 6])\n","  \n","  while goal == pos:\n","    goal = random.choice([3, 4, 5, 6])\n","    pos = random.choice([0, 1, 2, 3, 4, 5, 6])\n","\n","  direction = random.choice([\"cw\", \"ccw\"])\n","  state = [pos, direction, goal]\n","\n","  visualizer.reset(current_pos=state[0], goal = state[2])\n","  visualizer.plot()\n","\n","  while not converged:\n","    visualizer.update_pos(state[0], dir=state[1])\n","\n","    if state[0] == state[2]:\n","      converged = True\n","\n","    ## YOUR CODE HERE\n","    raise NotImplementedError(\n","        \"You have not written the while loop for pi_star rollout\")\n","    ####"],"metadata":{"id":"-1CRx-k7PM4y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import imageio\n","from IPython.display import Image\n","from tqdm.notebook import tqdm\n","\n","gif_path = os.path.join(fig_prog_folder, 'result.gif')\n","length = len([i for i in os.listdir(os.path.join(fig_prog_folder)) if \".png\" in i])\n","\n","with imageio.get_writer(gif_path, mode='I') as writer:\n","  for i in tqdm(range(length)):\n","    print(i, end='\\r')\n","    filename = os.path.join(fig_prog_folder, str(i)+\".png\")\n","    image = imageio.imread(filename)\n","    writer.append_data(image)\n","Image(open(gif_path,'rb').read(), width=400)"],"metadata":{"id":"FUj2kpsARVa0"},"execution_count":null,"outputs":[]}]}